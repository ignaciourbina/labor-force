{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8tMjmkQP-PDp"
      },
      "outputs": [],
      "source": [
        "\"\"\"cps_pipeline.py — Population counts by State × Occupation × Nativity × Employment\n",
        "====================================================================================\n",
        "This script builds CPS-style population estimates by\n",
        "  • State (FIPS)             – GESTFIPS\n",
        "  • Occupation (2018 SOC, primary job) – PTIO1OCD\n",
        "  • Foreign-born, not a U.S. citizen   – derived from PRCITSHP\n",
        "  • Employment status (Employed vs. Unemployed) – PREMPNOT\n",
        "for civilians age ≥ 16 who are **in** the civilian labor force.\n",
        "\n",
        "This version is simplified for use in a Google Colab or Jupyter notebook.\n",
        "Set the file paths in the \"Analysis Execution\" section at the bottom of the\n",
        "script, then run the entire script.\n",
        "\n",
        "Key features\n",
        "------------\n",
        "* **Case-insensitive import** – Reads your CSV without assuming upper- or lower-case\n",
        "  headers; all names are coerced to UPPER-CASE right after ingest, so the script\n",
        "  works no matter what your extraction software produced.\n",
        "* **Listwise deletion** before any transformations (on the analysis variable set)\n",
        "  to avoid weight distortions from missing values.\n",
        "* Outputs three CSVs: a variable dictionary, a long table, and a wide table.\n",
        "\n",
        "Dependencies: pandas ≥ 1.5.\n",
        "\"\"\"\n",
        "import pathlib\n",
        "import sys\n",
        "import pandas as pd\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "# These are the raw variable names required from the input CSV.\n",
        "RAW_COLS = [\n",
        "    \"GESTFIPS\", \"PRPERTYP\", \"PRTAGE\", \"PWCMPWGT\", \"PWORWGT\", \"PTIO1OCD\",\n",
        "    \"PRCITSHP\", \"PENATVTY\", \"PRINUYER\", \"PEMLR\", \"PRCIVLF\", \"PREMPNOT\",\n",
        "]\n",
        "\n",
        "# This map provides human-readable names for the raw CPS variables.\n",
        "RENAME_MAP = {\n",
        "    \"GESTFIPS\": \"state_fips\",\n",
        "    \"PRPERTYP\": \"person_type\",\n",
        "    \"PRTAGE\": \"age\",\n",
        "    \"PWCMPWGT\": \"weight_cmp\",\n",
        "    \"PWORWGT\": \"weight_or\",\n",
        "    \"PTIO1OCD\": \"occ2018\",\n",
        "    \"PRCITSHP\": \"citizenship\",\n",
        "    \"PENATVTY\": \"nativity_country\",\n",
        "    \"PRINUYER\": \"year_of_entry\",\n",
        "    \"PEMLR\": \"mlr_status\",\n",
        "    \"PRCIVLF\": \"in_civ_lf\",\n",
        "    \"PREMPNOT\": \"emp_recode\",\n",
        "}\n",
        "\n",
        "# This list provides content for the output variable dictionary CSV.\n",
        "DICTIONARY_ROWS = [\n",
        "    (\"state_fips\", \"GESTFIPS\", \"FIPS state code (household geography)\"),\n",
        "    (\"person_type\", \"PRPERTYP\", \"Person record type (should be 2 for civilians)\"),\n",
        "    (\"age\", \"PRTAGE\", \"Age in years\"),\n",
        "    (\"weight_cmp\", \"PWCMPWGT\", \"Composited person weight (4 implied decimals)\"),\n",
        "    (\"weight_or\", \"PWORWGT\", \"Outgoing-rotation weight (earnings analyses)\"),\n",
        "    (\"occ2018\", \"PTIO1OCD\", \"Primary job occupation — 2018 SOC cross-walked\"),\n",
        "    (\"citizenship\", \"PRCITSHP\", \"Citizenship/nativity recode\"),\n",
        "    (\"nativity_country\", \"PENATVTY\", \"Country of birth (nativity)\"),\n",
        "    (\"year_of_entry\", \"PRINUYER\", \"Year of entry into the U.S.\"),\n",
        "    (\"mlr_status\", \"PEMLR\", \"Monthly labor-force recode (7 categories)\"),\n",
        "    (\"in_civ_lf\", \"PRCIVLF\", \"Civilian labor force flag (1=in LF, 2=not in LF)\"),\n",
        "    (\"emp_recode\", \"PREMPNOT\", \"Employed/Unemployed/NILF recode\"),\n",
        "]\n",
        "\n",
        "# These are the variables used in the final analysis. Any record with a missing\n",
        "# value in one of these columns will be dropped (listwise deletion).\n",
        "ANALYSIS_VARS = [\n",
        "    \"state_fips\", \"occ2018\", \"age\", \"citizenship\", \"emp_recode\",\n",
        "    \"in_civ_lf\", \"weight_cmp\",\n",
        "]\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Helper functions\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def read_cps(path: pathlib.Path) -> pd.DataFrame:\n",
        "    \"\"\"Read CPS CSV and force all column names to upper-case.\"\"\"\n",
        "    print(\"→ Reading CPS extract…\", file=sys.stderr)\n",
        "    try:\n",
        "        df = pd.read_csv(path, low_memory=False)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file not found at {path}\", file=sys.stderr)\n",
        "        # In a notebook, it's better to raise an error than to exit.\n",
        "        raise\n",
        "\n",
        "    # Standardise header case to prevent case sensitivity issues.\n",
        "    df.columns = df.columns.str.upper()\n",
        "    print(f\"  Loaded {len(df):,} rows × {df.shape[1]} cols\", file=sys.stderr)\n",
        "    # Check that all required columns are present in the dataframe.\n",
        "    missing = sorted(set(RAW_COLS) - set(df.columns))\n",
        "    if missing:\n",
        "        raise KeyError(\n",
        "            f\"Input file lacks required column(s): {', '.join(missing)}.\\n\"\n",
        "            \"Ensure your extract includes those variables.\"\n",
        "        )\n",
        "    # Subset to only the raw variables needed for the pipeline.\n",
        "    return df[RAW_COLS].copy()\n",
        "\n",
        "\n",
        "def rename_vars(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Rename raw CPS variables to short, human-readable names.\"\"\"\n",
        "    return df.rename(columns=RENAME_MAP)\n",
        "\n",
        "\n",
        "def write_dictionary(outdir: pathlib.Path):\n",
        "    \"\"\"Save variable dictionary as a CSV file.\"\"\"\n",
        "    outdir.mkdir(parents=True, exist_ok=True)\n",
        "    dict_df = pd.DataFrame(DICTIONARY_ROWS, columns=[\"name\", \"source\", \"description\"])\n",
        "    dict_path = outdir / \"variable_dictionary.csv\"\n",
        "    dict_df.to_csv(dict_path, index=False)\n",
        "    print(f\"✓ Wrote {dict_path}\")\n",
        "\n",
        "\n",
        "def derive_flags(\n",
        "    df: pd.DataFrame,\n",
        "    *,\n",
        "    narrow: bool = False,          # ← set to True for the “non-citizen only” split\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Add nativity & employment flags.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : DataFrame\n",
        "        CPS micro-data after renaming.\n",
        "    narrow : bool, default False\n",
        "        • False → 'nativity_flag' = 1 if PRCITSHP in {4, 5}  (foreign-born, BLS Table A-7)\n",
        "        • True  → 'nativity_flag' = 1 if PRCITSHP     == 5   (foreign-born non-citizen)\n",
        "\n",
        "    Columns created\n",
        "    ---------------\n",
        "    foreign_born      (1 = PRCITSHP in {4, 5})\n",
        "    non_cit_foreign   (1 = PRCITSHP == 5)\n",
        "    nativity_flag     (whichever of the above is selected by *narrow*)\n",
        "    emp_status        ('EMPLOYED' / 'UNEMPLOYED')\n",
        "    \"\"\"\n",
        "    # ── citizenship flags ────────────────────────────────────────────────\n",
        "    cit_num = pd.to_numeric(df[\"citizenship\"], errors=\"coerce\")\n",
        "\n",
        "    df[\"foreign_born\"]    = cit_num.isin([4, 5]).astype(int)\n",
        "    df[\"non_cit_foreign\"] = (cit_num == 5).astype(int)\n",
        "\n",
        "    # master flag used in the later collapse\n",
        "    df[\"nativity_flag\"] = (\n",
        "        df[\"non_cit_foreign\"] if narrow else df[\"foreign_born\"]\n",
        "    )\n",
        "\n",
        "    # ── employment-status flag ───────────────────────────────────────────\n",
        "    emp_num = pd.to_numeric(df[\"emp_recode\"], errors=\"coerce\")\n",
        "    df[\"emp_status\"] = emp_num.map({1: \"EMPLOYED\", 2: \"UNEMPLOYED\"})\n",
        "\n",
        "    # keep only records that mapped successfully (drop NILF 3/4 & miscoded)\n",
        "    return df[~df[\"emp_status\"].isna()].copy()\n",
        "\n",
        "\n",
        "\n",
        "def listwise_delete(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
        "    \"\"\"Drop any record with a missing value in *any* of the given columns.\"\"\"\n",
        "    before = len(df)\n",
        "    df2 = df.dropna(subset=cols)\n",
        "    after = len(df2)\n",
        "    if (before - after) > 0:\n",
        "        print(f\"→ Listwise deletion: dropped {before - after:,} rows with missing values\", file=sys.stderr)\n",
        "    return df2\n",
        "\n",
        "\n",
        "def filter_to_universe(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Keep only civilians aged 16+ who are in the civilian labor force.\"\"\"\n",
        "    # --- Debugging ---\n",
        "    # Show the unique values in the column used for filtering to help diagnose data issues.\n",
        "    print(\"--- Debug Info ---\", file=sys.stderr)\n",
        "    print(\"Unique values in 'in_civ_lf' column before filtering:\", df['in_civ_lf'].unique(), file=sys.stderr)\n",
        "    print(\"--------------------\", file=sys.stderr)\n",
        "    # -----------------\n",
        "\n",
        "    # The universe is defined by age and civilian labor force status (PRCIVLF == 1).\n",
        "    # Using pd.to_numeric is more robust and handles cases where the data might\n",
        "    # be a float (1.0) or string ('1') instead of just an integer.\n",
        "    mask = (df[\"age\"] >= 16) & (pd.to_numeric(df[\"in_civ_lf\"], errors='coerce') == 1)\n",
        "    filtered = df[mask].copy()\n",
        "    print(f\"→ Subset to civilians 16+ in LF: {len(filtered):,} rows remain\", file=sys.stderr)\n",
        "    return filtered\n",
        "\n",
        "\n",
        "def get_weighted_counts(\n",
        "    df: pd.DataFrame,\n",
        "    *,\n",
        "    weight_col: str = \"weight_cmp\",     # ← choose \"weight_or\", \"weight_cmp\", etc.\n",
        "    implied_decimals: int = 4,          # 4 for PWCMPWGT / PWORWGT, 0 for pre-scaled\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Collapse the person-level file to weighted counts by\n",
        "    state × occupation × nativity × employment.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : DataFrame\n",
        "        Person-level CPS data after derive_flags() and universe filtering.\n",
        "    weight_col : str, default \"weight_cmp\"\n",
        "        Column in *df* that contains the raw weight.\n",
        "    implied_decimals : int, default 4\n",
        "        Number of implied decimals in the stored weight.  The function will\n",
        "        divide by 10**implied_decimals to obtain the real-scale weight.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    DataFrame\n",
        "        One row per (state_fips, occ2018, nativity_flag, emp_status)\n",
        "        with a 'population' column of weighted counts.\n",
        "    \"\"\"\n",
        "    # ------------------------------------------------------------------\n",
        "    if weight_col not in df.columns:\n",
        "        raise KeyError(f\"{weight_col!r} not found in DataFrame columns.\")\n",
        "\n",
        "    scale = 10 ** implied_decimals\n",
        "    df[\"_wt\"] = df[weight_col] / scale\n",
        "\n",
        "    group_cols = [\"state_fips\", \"occ2018\", \"nativity_flag\", \"emp_status\"]\n",
        "\n",
        "    out = (\n",
        "        df.groupby(group_cols, dropna=False)[\"_wt\"]\n",
        "          .sum()\n",
        "          .reset_index(name=\"population\")\n",
        "    )\n",
        "\n",
        "    print(\"→ Collapsed to weighted counts\", file=sys.stderr)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "def pivot_wide(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Convert long EMPLOYED/UNEMPLOYED rows into wide columns.\"\"\"\n",
        "    wide = df.pivot_table(\n",
        "        index=[\"state_fips\", \"occ2018\", \"nativity_flag\"],\n",
        "        columns=\"emp_status\",\n",
        "        values=\"population\",\n",
        "        fill_value=0,\n",
        "    ).reset_index()\n",
        "    wide.columns.name = None\n",
        "    return wide\n",
        "\n",
        "def pad_occ_codes(df: pd.DataFrame, col: str = \"occ2018\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Ensure that the occupation codes are zero-padded, 4-character strings.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    10     -> '0010'\n",
        "    '7110' -> '7110'\n",
        "    NaN    -> NaN  (left untouched to preserve missingness)\n",
        "    \"\"\"\n",
        "    df[col] = (\n",
        "        df[col]                       # raw column\n",
        "          .apply(pd.to_numeric, errors=\"coerce\")   # make sure we’re numeric\n",
        "          .astype(\"Int64\")            # Pandas nullable integer → keeps NaNs\n",
        "          .astype(str)                # → string\n",
        "          .str.zfill(4)               # zero-pad to width 4\n",
        "    )\n",
        "    return df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW413RolPLc4",
        "outputId": "3c991515-cb62-4816-ffc1-bc15353a2eb6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "→ Reading CPS extract…\n",
            "  Loaded 123,461 rows × 393 cols\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Wrote /content/drive/MyDrive/cps_occup_data/results/variable_dictionary.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "→ Listwise deletion: dropped 28,434 rows with missing values\n",
            "--- Debug Info ---\n",
            "Unique values in 'in_civ_lf' column before filtering: [1.]\n",
            "--------------------\n",
            "→ Subset to civilians 16+ in LF: 46,511 rows remain\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Wrote /content/drive/MyDrive/cps_occup_data/results/cps_state_occ_nat_emp_raw_non_collapsed.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "→ Collapsed to weighted counts\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Wrote /content/drive/MyDrive/cps_occup_data/results/cps_state_occ_nat_emp_long.csv\n",
            "✓ Wrote /content/drive/MyDrive/cps_occup_data/results/cps_state_occ_nat_emp_wide.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Pipeline finished successfully.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Analysis Execution\n",
        "# -----------------------------------------------------------------------------\n",
        "# TODO: Set your file paths here\n",
        "# -----------------------------------------------------------------------------\n",
        "# Path to your input CPS CSV file.\n",
        "# For Colab, you might upload this or access it from Google Drive.\n",
        "# Example: cps_csv_path = pathlib.Path('/content/cps_data.csv')\n",
        "cps_csv_path = pathlib.Path(r\"/content/drive/MyDrive/cps_occup_data/basic_cps.csv\")\n",
        "\n",
        "# Path to the directory where you want to save the output files.\n",
        "# Example: output_dir = pathlib.Path('/content/results/')\n",
        "output_dir = pathlib.Path(\"/content/drive/MyDrive/cps_occup_data/results/\")\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Create the output directory if it doesn't exist.\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- Run the pipeline by calling the functions in order ---\n",
        "df_raw = read_cps(cps_csv_path)\n",
        "df_renamed = rename_vars(df_raw)\n",
        "\n",
        "# Pad occupation codes (must come *before* listwise_delete)\n",
        "df_renamed = pad_occ_codes(df_renamed)\n",
        "\n",
        "# Save variable dictionary (once per run).\n",
        "write_dictionary(output_dir)\n",
        "\n",
        "# Listwise deletion on analysis variables (before LF filters).\n",
        "df_clean = listwise_delete(df_renamed, ANALYSIS_VARS)\n",
        "\n",
        "# Explicitly create a copy after filtering to prevent SettingWithCopyWarning.\n",
        "# This ensures that derive_flags operates on a clean, independent DataFrame.\n",
        "df_derived = derive_flags(df_clean.copy())\n",
        "df_lf = filter_to_universe(df_derived)\n",
        "\n",
        "# Save raw data - cleaned and filtered\n",
        "df_lf_path = output_dir / \"cps_state_occ_nat_emp_raw_non_collapsed.csv\"\n",
        "df_lf.to_csv(df_lf_path, index=False)\n",
        "print(f\"✓ Wrote {df_lf_path}\")\n",
        "\n",
        "# Collapse to a long table of weighted counts.\n",
        "long_tbl = get_weighted_counts(df_lf, weight_col=\"weight_cmp\")\n",
        "long_path = output_dir / \"cps_state_occ_nat_emp_long.csv\"\n",
        "long_tbl.to_csv(long_path, index=False)\n",
        "print(f\"✓ Wrote {long_path}\")\n",
        "\n",
        "# Pivot the long table into a wide format.\n",
        "wide_tbl = pivot_wide(long_tbl)\n",
        "wide_path = output_dir / \"cps_state_occ_nat_emp_wide.csv\"\n",
        "wide_tbl.to_csv(wide_path, index=False)\n",
        "print(f\"✓ Wrote {wide_path}\")\n",
        "\n",
        "print(\"\\nPipeline finished successfully.\", file=sys.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "xaKrlYTvIRIs",
        "outputId": "721989bf-fda1-4bbe-cbb4-d4137a658f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(46511, 16)\n",
            "(16085, 5)\n",
            "(15042, 5)\n",
            "Unique states        : 51\n",
            "Unique occupations   : 523\n",
            "Citizenship flags    : 2\n",
            "Theoretical row count: 53,346\n",
            "Actual wide rows     : 15,042\n",
            "⚠  Wide table is missing 38304 cells (28.2% coverage).\n",
            "\n",
            "First few missing cells:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    display(missing\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"state_fips\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occ2018\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"4720\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nativity_flag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b00d15b2-fd08-44b4-85ee-e3bfe5bf3067\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state_fips</th>\n",
              "      <th>occ2018</th>\n",
              "      <th>nativity_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5400</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4720</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>5840</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>4920</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>3870</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b00d15b2-fd08-44b4-85ee-e3bfe5bf3067')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b00d15b2-fd08-44b4-85ee-e3bfe5bf3067 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b00d15b2-fd08-44b4-85ee-e3bfe5bf3067');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-65bdf168-089e-4df3-976a-3622fe580e99\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-65bdf168-089e-4df3-976a-3622fe580e99')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-65bdf168-089e-4df3-976a-3622fe580e99 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   state_fips occ2018  nativity_flag\n",
              "1           1    5400              1\n",
              "3           1    4720              1\n",
              "5           1    5840              1\n",
              "7           1    4920              1\n",
              "9           1    3870              1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "raw_path = pathlib.Path(\"/content/drive/MyDrive/cps_occup_data/results/cps_state_occ_nat_emp_raw_non_collapsed.csv\")\n",
        "long_tbl = pd.read_csv(raw_path)\n",
        "print(long_tbl.shape)\n",
        "long_tbl.head()\n",
        "\n",
        "long_path = pathlib.Path(\"/content/drive/MyDrive/cps_occup_data/results/cps_state_occ_nat_emp_long.csv\")\n",
        "long_tbl = pd.read_csv(long_path)\n",
        "print(long_tbl.shape)\n",
        "long_tbl.head()\n",
        "\n",
        "wide_path = pathlib.Path(\"/content/drive/MyDrive/cps_occup_data/results/cps_state_occ_nat_emp_wide.csv\")\n",
        "wide_tbl = pd.read_csv(wide_path)\n",
        "print(wide_tbl.shape)\n",
        "wide_tbl.head()\n",
        "\n",
        "# Make sure that the occupation codes are zero-padded, 4-character strings.\n",
        "df_lf[\"occ2018\"]   = df_lf[\"occ2018\"].astype(str).str.zfill(4)\n",
        "wide_tbl[\"occ2018\"] = wide_tbl[\"occ2018\"].astype(str).str.zfill(4)\n",
        "\n",
        "# ── FINAL COMPLETENESS CHECK ────────────────────────────────────────────────\n",
        "# 1. Unique dimension counts in the *pre-collapse* universe\n",
        "u_states = df_lf[\"state_fips\"].nunique()\n",
        "u_occ    = df_lf[\"occ2018\"].nunique()\n",
        "u_cit    = df_lf[\"non_cit_foreign\"].nunique()   # should be 2 (0 / 1)\n",
        "\n",
        "theoretical_rows = u_states * u_occ * u_cit\n",
        "actual_rows      = wide_tbl.shape[0]\n",
        "\n",
        "print(f\"Unique states        : {u_states}\")\n",
        "print(f\"Unique occupations   : {u_occ}\")\n",
        "print(f\"Citizenship flags    : {u_cit}\")\n",
        "print(f\"Theoretical row count: {theoretical_rows:,}\")\n",
        "print(f\"Actual wide rows     : {actual_rows:,}\")\n",
        "\n",
        "# 2. Quick pass / warn\n",
        "if actual_rows == theoretical_rows:\n",
        "    print(\"✓  Wide table has every possible State × Occupation × Citizenship cell.\")\n",
        "else:\n",
        "    print(\"⚠  Wide table is missing\",\n",
        "          theoretical_rows - actual_rows, \"cells \"\n",
        "          f\"({actual_rows / theoretical_rows:.1%} coverage). Note: Sparcity is expected.\")\n",
        "\n",
        "    # 3. (Optional) list first few missing combinations\n",
        "    #    Build the full Cartesian product, outer-merge, and flag empties\n",
        "    import itertools as it\n",
        "    import pandas as pd\n",
        "\n",
        "    full_index = pd.MultiIndex.from_product(\n",
        "        [df_lf[\"state_fips\"].unique(),\n",
        "         df_lf[\"occ2018\"].unique(),\n",
        "         df_lf[\"nativity_flag\"].unique()],\n",
        "        names=[\"state_fips\", \"occ2018\", \"nativity_flag\"]\n",
        "    ).to_frame(index=False)\n",
        "\n",
        "    missing = (\n",
        "        pd.MultiIndex.from_product(\n",
        "            [df_lf[\"state_fips\"].unique(),\n",
        "            df_lf[\"occ2018\"].unique(),\n",
        "            df_lf[\"nativity_flag\"].unique()],\n",
        "            names=[\"state_fips\", \"occ2018\", \"nativity_flag\"]\n",
        "        ).to_frame(index=False)\n",
        "          .merge(wide_tbl[[\"state_fips\",\"occ2018\",\"nativity_flag\"]],\n",
        "                on=[\"state_fips\",\"occ2018\",\"nativity_flag\"],\n",
        "                how=\"left\", indicator=True)\n",
        "          .query(\"_merge == 'left_only'\")\n",
        "          .drop(columns=\"_merge\")\n",
        "    )\n",
        "\n",
        "    print(\"\\nFirst few missing cells:\")\n",
        "    display(missing.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVKQAk_cJKdD",
        "outputId": "d3b081c8-3e8b-4050-930a-b622cfb2304f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Sanity checks passed: 51 states, 523 occupations, person-weight total 170,215,952.86\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# sanity_checks.py  – run after wide_tbl is created\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "import numpy as np\n",
        "\n",
        "# ❶  Counts BEFORE collapse (df_lf = final person-level universe)\n",
        "states_before = df_lf[\"state_fips\"].nunique()\n",
        "occ_before    = df_lf[\"occ2018\"].nunique()\n",
        "weight_before = (df_lf[\"weight_cmp\"] / 1e4).sum()        # composited weight\n",
        "\n",
        "# ❷  Counts AFTER wide pivot\n",
        "states_after = wide_tbl[\"state_fips\"].nunique()\n",
        "occ_after    = wide_tbl[\"occ2018\"].nunique()\n",
        "weight_after = wide_tbl[[\"EMPLOYED\", \"UNEMPLOYED\"]].sum().sum()\n",
        "\n",
        "# ❸  Assertions\n",
        "assert states_before == states_after, \\\n",
        "    f\"State count changed!  before {states_before}  after {states_after}\"\n",
        "\n",
        "assert occ_before == occ_after, \\\n",
        "    f\"Occupation count changed!  before {occ_before}  after {occ_after}\"\n",
        "\n",
        "tol = 1e-6 * weight_before           # tolerance for float rounding\n",
        "assert np.isclose(weight_before, weight_after, atol=tol), \\\n",
        "    f\"Person-weight total drifted!  before {weight_before:.2f}  after {weight_after:.2f}\"\n",
        "\n",
        "print(\"✓ Sanity checks passed:\",\n",
        "      f\"{states_after} states,\",\n",
        "      f\"{occ_after} occupations,\",\n",
        "      f\"person-weight total {weight_after:,.2f}\")\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEK45dT4JdVr",
        "outputId": "c9b098ec-3d8d-4e14-f6ef-cc832e79bf4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique occupation codes BEFORE any row-wise deletion: 524\n"
          ]
        }
      ],
      "source": [
        "# curiosity check ────────────────────────────────────────────────────────────\n",
        "# df_renamed is the DataFrame produced by rename_vars(df_raw)\n",
        "occ_unique_pre_delete = (\n",
        "    pd.to_numeric(df_renamed[\"occ2018\"], errors=\"coerce\")\n",
        "      .dropna()                     # ignore blanks / NIU\n",
        "      .nunique()\n",
        ")\n",
        "\n",
        "print(f\"Unique occupation codes BEFORE any row-wise deletion: {occ_unique_pre_delete}\")\n",
        "# ────────────────────────────────────────────────────────────────────────────\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ab3GcgqLQh9",
        "outputId": "c80eb29a-dc66-47d4-ef4a-ca258a89d572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Employed persons   : 163,400,882\n",
            "Unemployed persons : 6,815,071\n",
            "Unemployment rate  : 4.0038%\n"
          ]
        }
      ],
      "source": [
        "# national_totals.py  – sanity-check unemployment rate\n",
        "import pandas as pd, pathlib\n",
        "\n",
        "wide_tbl = pd.read_csv(pathlib.Path(\"/content/drive/MyDrive/cps_occup_data/results/cps_state_occ_nat_emp_wide.csv\"))\n",
        "\n",
        "nat = wide_tbl[[\"EMPLOYED\", \"UNEMPLOYED\"]].sum()      # collapse to U.S. total\n",
        "unemp_rate = nat[\"UNEMPLOYED\"] / nat.sum()            # rate = U / (E+U)\n",
        "\n",
        "print(f\"Employed persons   : {nat['EMPLOYED']:,.0f}\")\n",
        "print(f\"Unemployed persons : {nat['UNEMPLOYED']:,.0f}\")\n",
        "print(f\"Unemployment rate  : {unemp_rate:.4%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "G_9dwW5XMy7n",
        "outputId": "b4efe052-1a5b-40e4-faa9-e78bbae4e797"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_d43ff\" class=\"dataframe\">\n",
              "  <caption>Employment Summary by Nativity</caption>\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_d43ff_level0_col0\" class=\"col_heading level0 col0\" >EMPLOYED</th>\n",
              "      <th id=\"T_d43ff_level0_col1\" class=\"col_heading level0 col1\" >UNEMPLOYED</th>\n",
              "      <th id=\"T_d43ff_level0_col2\" class=\"col_heading level0 col2\" >Unemployment_rate</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >nativity_flag</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "      <th class=\"blank col2\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_d43ff_level0_row0\" class=\"row_heading level0 row0\" >Native-born</th>\n",
              "      <td id=\"T_d43ff_row0_col0\" class=\"data row0 col0\" >131,857,251.5483</td>\n",
              "      <td id=\"T_d43ff_row0_col1\" class=\"data row0 col1\" >5,688,127.2236</td>\n",
              "      <td id=\"T_d43ff_row0_col2\" class=\"data row0 col2\" >4.14%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d43ff_level0_row1\" class=\"row_heading level0 row1\" >Foreign, non-citizen</th>\n",
              "      <td id=\"T_d43ff_row1_col0\" class=\"data row1 col0\" >31,543,630.7106</td>\n",
              "      <td id=\"T_d43ff_row1_col1\" class=\"data row1 col1\" >1,126,943.3784</td>\n",
              "      <td id=\"T_d43ff_row1_col2\" class=\"data row1 col2\" >3.45%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7b92fa8524d0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- 1.  Load the wide file -------------------------------------------------\n",
        "wide_path = \"/content/drive/MyDrive/cps_occup_data/results/cps_state_occ_nat_emp_wide.csv\"   # adjust if you saved elsewhere\n",
        "wide_tbl  = pd.read_csv(wide_path)\n",
        "\n",
        "# --- 2.  Collapse to native vs foreign --------------------------------------\n",
        "summary = (\n",
        "    wide_tbl\n",
        "      .groupby(\"nativity_flag\")[[\"EMPLOYED\", \"UNEMPLOYED\"]]\n",
        "      .sum()\n",
        "      .rename(index={0: \"Native-born\", 1: \"Foreign, non-citizen\"})\n",
        ")\n",
        "\n",
        "summary[\"Unemployment_rate\"] = summary[\"UNEMPLOYED\"] / (summary[\"EMPLOYED\"] + summary[\"UNEMPLOYED\"])\n",
        "\n",
        "# --- 3.  View the result ----------------------------------------------------\n",
        "def format_table(df):\n",
        "    return df.style.format({\n",
        "        \"EMPLOYED\": \"{:,}\",\n",
        "        \"UNEMPLOYED\": \"{:,}\",\n",
        "        \"Unemployment_rate\": \"{:.2%}\"\n",
        "    }).set_caption(\"Employment Summary by Nativity\")\n",
        "\n",
        "format_table(summary)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS2hrA_rSM_I",
        "outputId": "f2e9a76e-f047-402b-9373-6741318041b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Wrote padded wide file with zeros for missing cells\n"
          ]
        }
      ],
      "source": [
        "# --- pad missing State×Occupation×Citizenship cells with zeros ---------------\n",
        "full_index = pd.MultiIndex.from_product(\n",
        "    [\n",
        "        df_lf[\"state_fips\"].unique(),         # 51 states\n",
        "        df_lf[\"occ2018\"].unique(),            # 523 occ codes in the filtered file\n",
        "        [0, 1],                               # citizenship flags: native / non-cit-foreign\n",
        "    ],\n",
        "    names=[\"state_fips\", \"occ2018\", \"nativity_flag\"]\n",
        ")\n",
        "\n",
        "wide_complete = (\n",
        "    wide_tbl\n",
        "      .set_index([\"state_fips\",\"occ2018\",\"nativity_flag\"])\n",
        "      .reindex(full_index, fill_value=0)      # inject zeros\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "# save or use wide_complete instead of wide_tbl\n",
        "wide_complete.to_csv(output_dir / \"cps_state_occ_nat_emp_wide_full.csv\", index=False)\n",
        "print(\"✓ Wrote padded wide file with zeros for missing cells\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiPq40Ni6QyX",
        "outputId": "7a95c847-5971-4233-e3ee-8fc1fcee42d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Wrote results/cps_state_labor_force_totals.csv\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/cps_occup_data/state_labor_force_table.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4ARiCAe9Wfg",
        "outputId": "b09417f6-a223-451b-8aec-6442c0f09f1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Wrote results/cps_occ_labor_force_totals.csv\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/cps_occup_data/occupation_labor_force_table.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
